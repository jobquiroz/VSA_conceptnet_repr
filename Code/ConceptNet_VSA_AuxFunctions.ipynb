{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It defines the functions to be used in *ConceptNet_VSA* notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats.stats import spearmanr\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Vital function for pairwise distances...\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading SimLex-999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_SimLex():\n",
    "    df = pd.read_excel('../Data/SimLex.xlsx') \n",
    "\n",
    "    # Selecting only Nouns\n",
    "    df = df[df['POS'] == 'N']\n",
    "\n",
    "    # Pairs\n",
    "    Pairs = df[['word1','word2','SimLex999']].values.tolist()\n",
    "    Pairs = [[str(x[0]), str(x[1]), float(x[2])] for x  in Pairs]\n",
    "\n",
    "    # List of concepts\n",
    "    Concepts = pd.unique(df[['word1','word2']].values.ravel('K'))\n",
    "    Concepts = list(map(str, Concepts))\n",
    "    print(\"There are\", len(Concepts), \"concepts\")\n",
    "    return Pairs,Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_concept_in_pairs (C, Pair_list, thr, G):\n",
    "    \"Given a single concept C, it returns a lists of pairs where C appears\"\n",
    "    for p in Pair_list:\n",
    "        if C == p[0] and p[2] > thr : \n",
    "            if p[1] not in G:\n",
    "                G.extend(find_concept_in_pairs(p[1], Pair_list, thr, G + [p[1]]))\n",
    "        elif C == p[1] and p[2] > thr: \n",
    "            if p[0] not in G:\n",
    "                G.extend(find_concept_in_pairs(p[0], Pair_list, thr, G + [p[0]]))\n",
    "\n",
    "    return list(set(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_s = 0     # Threshold value\n",
    "\n",
    "def CreatingPartitions ():\n",
    "    Groups = []\n",
    "    for pair in Pairs:\n",
    "        g = find_concept_in_pairs(pair[0], Pairs, thr_s, [pair[0]])\n",
    "        g.sort()\n",
    "        if g not in Groups:\n",
    "            Groups.append(g)\n",
    "\n",
    "    # Sorting\n",
    "    Groups.sort()\n",
    "    Groups.sort(key = len, reverse = True)\n",
    "\n",
    "    # Filtering out partitions of size 1 (only 1 pair)\n",
    "    Groups = [x for x in Groups if len(x) > 1]\n",
    "\n",
    "    print(\"There are\",len(Groups),\"partitions\")\n",
    "    return Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pairs_per_Partition(Save = None):\n",
    "    i = -1\n",
    "    GPairs = []\n",
    "    for G in Groups:\n",
    "        i += 1 # Contador de grupos...\n",
    "        gPairs = []\n",
    "        for j in range(len(G)): # Por concepto en grupo i...\n",
    "            for k in range(j+1, len(G)):\n",
    "                for p in Pairs:\n",
    "                    if G[j] in p and G[k] in p and p[2] > thr_s:\n",
    "                        gPairs.append(p)\n",
    "                        #print p\n",
    "        if Save:\n",
    "            np.save('../Data/ClusteringData/01 Elementos/Elementos_Grupo' + str(i), G)\n",
    "            np.save('../Data/ClusteringData/02 Parejas/Parejas_Grupo' + str(i), gPairs)\n",
    "        \n",
    "        # Lista de parejas, ordenadas de menor a mayor similitud [para cada grupo]\n",
    "        GPairs.append(sorted(gPairs, key = lambda x: x[2]))\n",
    "    return GPairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading semantic features file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatt2 (L):\n",
    "    \"Formatting the imported file into an array\"\n",
    "    new = L[:3] + [eval(L[3].replace(' ',','))] + [float(L[4])] + [float(L[5])]\n",
    "    return new\n",
    "\n",
    "\n",
    "def Reading_Feature_Matrix():\n",
    "    Features_matrix = []\n",
    "    # Reading csv file\n",
    "    with open('../Data/ConceptNet_Semantic_Features.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        count = 0\n",
    "        for row in csv_reader:\n",
    "            if count > 0:\n",
    "                Features_matrix.append(formatt2(row))\n",
    "            else:\n",
    "                count = 1;\n",
    "    csv_file.close()\n",
    "    \n",
    "    # Formatting\n",
    "    concept_in = Features_matrix[0][0]  #initial concept\n",
    "    Feat_matrix = [[] for i in range(751)]        \n",
    "\n",
    "    # Loop for formatting\n",
    "    i = 0\n",
    "    features_concept_i = []\n",
    "    for feat in Features_matrix:\n",
    "        # Same concept... \n",
    "        if feat[0] == concept_in:\n",
    "            # Adding 'feat' to aux array\n",
    "            features_concept_i.append(feat)\n",
    "        else:\n",
    "           # Changing concept\n",
    "            concept_in = feat[0]\n",
    "           # Copying aux array to final array\n",
    "            Feat_matrix[i] = features_concept_i[:]\n",
    "           # Clearing aux array and increasing counter\n",
    "            features_concept_i = [feat]\n",
    "            i += 1\n",
    "\n",
    "    Feat_matrix[i] = features_concept_i[:]\n",
    "\n",
    "    # Sorting Feat_matrix based on weight (x[4])\n",
    "    for con in Feat_matrix:\n",
    "        con.sort(key = lambda x: x[4], reverse = True)\n",
    "    \n",
    "    return Feat_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA0) Function to extract relevant relations after clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrac_relation_name (string):\n",
    "    \"Given a file name as: 'Group_0_Relation_AtLocation.npy' it extracts the relation name ('AtLocation'\"\n",
    "    # Reversing string\n",
    "    string = string[::-1]\n",
    "    f1 = string.find('_')\n",
    "    f2 = string.find('.')\n",
    "    return string[f2+1:f1][::-1]\n",
    "# extrac_relation_name('Group_0_Relation_IsA.npy')  -> 'IsA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA1) Locating feature in a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_to_cluster (L_clus, feat_val):\n",
    "    \"Giving a feature value it returns the number of the cluster in which it is located...\"\n",
    "    for i in range(len(L_clus)):\n",
    "        if feat_val in L_clus[i]:\n",
    "            return i   # Cluster numbering starts in 1 (not 0)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA2) Contamination Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contamina_vec(array, dif_bits):\n",
    "    \"Dado un arreglo binario y un número entero, se regresa otro arreglo con una distancia de Hamming de dif_bits del \\\n",
    "    primero...\"\n",
    "    new_array = array.copy()\n",
    "    index_randm = np.random.randint(0, len(array)-1, dif_bits)\n",
    "    for i in np.unique(index_randm):\n",
    "        if new_array[i] == 0:\n",
    "            new_array[i] = 1\n",
    "        else:\n",
    "            new_array[i] = 0\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA3) Función para cambiar definiciones de diccionario global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dict_defs (list_concepts, rela, features_list, i_grupo):\n",
    "    \"Dados un concepto y una lista de feature_values (no-lemmatizados) cambia la definición del concepto al añadir \\\n",
    "    a la cadena de feature_value parte del nombre de la relación a la cual está asociado. Por ejemplo, si el concepto \\\n",
    "    bed tiene los features:  IsA * furniture + RelatedTo * furniture + ...  \\\n",
    "    suponiendo que furniture es parte de la lista list_features y la relat es [IsA, RelatedTo] \\\n",
    "    entonces la definición de bed se modifica como IsA * furnitureIsA + RelatedTo * furniture + ...\"\n",
    "    # El diccionario de definiciones es global.\n",
    "    global Dict_defs\n",
    "    # Bucle sobre features en definición...\n",
    "    for con in list_concepts:\n",
    "        for f in Dict_defs[con]:\n",
    "            if f[0] == rela and f[1] in features_list: # si está en las relaciones que se están buscando...\n",
    "                f[1] = f[1] + '_' + f[0][:5] + f[0][-2:] + \"_g\" + str(i_grupo) # Se añaden letras identificadoras de feat_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA4) Get Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Pairs(concept_name):\n",
    "    \"Given a concept name, this function returns a list of the pairs where the input concept name is present...\"\n",
    "    global Groups, Gpairs\n",
    "    \n",
    "    concep_pairs = []\n",
    "    \n",
    "    for i_g in range(len(Groups)):\n",
    "        if concept_name in Groups[i_g]:\n",
    "            for pair_g in GPairs[i_g]:\n",
    "                if pair_g[0] == concept_name or pair_g[1] == concept_name:\n",
    "                    concep_pairs.append(pair_g)\n",
    "    return concep_pairs\n",
    "\n",
    "#get_Pairs('alcohol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA5) get_feat_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_values(Definition_list, feat_namm):\n",
    "    \"Given a definition list (the ones obtained from Dict_defs) and a feat_name, it returns a list with all the feature \\\n",
    "    values within the definition for such feature name\"\n",
    "    return [x[1] for x in Definition_list if x[0] == feat_namm]\n",
    "\n",
    "#get_feat_values(Dict_defs['cocktail'], 'RelatedTo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA6) Delete_relation_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_relation_code (string):\n",
    "    \"Given a string of a feature_value + unique code, it removes the unique code and returns the original feature value \\\n",
    "    e.g. 'human_IsAsA_g0' -> 'human' , 'learn_church_positions_UsedFor_g0' -> 'learn_church_positions'\" \n",
    "    \n",
    "    nums = '0123456789'\n",
    "    \n",
    "    # Reverse string\n",
    "    reversed_string = string[::-1]\n",
    "    # find first '_'\n",
    "    first = reversed_string.find('_')\n",
    "    \n",
    "    # Primero se debe verificar si la palabra tiene relation_code..\n",
    "    # Caso 1: no hay ningun '_'...\n",
    "    if first < 0:\n",
    "        return string\n",
    "    \n",
    "    last_two = string[-first:][:2]\n",
    "    if last_two[0] == 'g' and last_two[1] in nums:  # Se verifica que tiene g + number..\n",
    "        # Second '_'\n",
    "        second = reversed_string.find('_', first+1)\n",
    "        # Final string...\n",
    "        return string[:-second-1]\n",
    "    else:\n",
    "        return string  # tiene '_' pero no tiene g + number\n",
    "\n",
    "#print delete_relation_code('human_IsAsA_g0')\n",
    "#print delete_relation_code('bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA7) Find intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrando features que aparecen en todas las sublistas... Reduce con intersección..\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
